{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CREATING RETREVIAL ARGUMENTED GENERATION\n",
        "- Here we have various steps involved\n",
        "  - load the data by langchain\n",
        "  - split the data by langchain\n",
        "  - select the embidding (or) tokenzier model like Gpt,gemini,bert\n",
        "  - now create a vector database called chroma(here pass the splited data,model)\n",
        "  - now create new question pass to vector database\n",
        "  - now it will do dotproduct which is have more probability and gives output"
      ],
      "metadata": {
        "id": "pNnz2jt1xkoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP-1\n",
        "- INSTALL THE QERUIRED PACKAGES\n",
        "  - pip install langchain(BASIC)\n",
        "  - pip install langchain-community(LOAD THE DOCUMENT OR DATA)\n",
        "  - pip install langchain-text-splitters (TO SPLIT THE DOCUMENT)\n",
        "  - pip install langchain-google-genai(gemini_model)\n",
        "  - pip install sentence-transformers(for embidding)\n",
        "  - pip install langchain-chroma(vector data_base)\n",
        "  - pip install pyPdf(to read the pdf_file)\n",
        "**AFTER SUCESSFULLY COMPLTED INSTALING IMPORT THEM**\n"
      ],
      "metadata": {
        "id": "G3wJXyYjy1lJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP-2\n",
        "- IMPORT THEM"
      ],
      "metadata": {
        "id": "oTf3JoWI0_8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader #READ TEXT FILE\n",
        "from langchain_text_splitters import CharacterTextSplitter # split the documnent\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings # for embiddings\n",
        "from langchain_chroma import Chroma # for vector database"
      ],
      "metadata": {
        "id": "-k1vT5awxfgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AS OF NOW WE REQUIRD THESE FOUR PACKAGES**"
      ],
      "metadata": {
        "id": "6cYp1Rwv2U1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD THE DATA (or) DOCUMENT\n",
        "- Text Data"
      ],
      "metadata": {
        "id": "TLXEXHHm2cNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path=TextLoader('/content/chatbot.txt')\n",
        "text_data=path.load()\n",
        "#print(text_data[0].page_content)\n",
        "#we given this because data is in list\n",
        "# to axcess it we given this"
      ],
      "metadata": {
        "id": "Uybb0kjt23MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPLIT THE DOCUMENT"
      ],
      "metadata": {
        "id": "-nTkyPNKxgPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_method=CharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
        "splited_data=split_method.split_documents(text_data)\n",
        "print(len(splited_data))\n",
        "# HERE OUR DATA IS SPLITED INTO 8 DOCUMENTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PtEHOW15m6R",
        "outputId": "77dd1f62-e543-4d18-fea6-668bc0f5980d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1103, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SELECT OUR EMBIDDING MODEL\n",
        "- TO CONVERT WORDS TO EMBIDDINGS\n",
        "  - BERT TRANSFORMERS\n",
        "  - CHATGPT\n",
        "  - GEMINIAI"
      ],
      "metadata": {
        "id": "AR-1Mvvq69pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMB_MODEL=SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')# all-MiniLM-L6-v2 model_name\n",
        "EMB_MODEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnTGV9dH8F-C",
        "outputId": "362a3f50-d27d-43f4-b564-484fb5973b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              "), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VECTOR DATA_BASE(Chroma)\n",
        "- HERE PASS THE SPLIT DATA,EMB_MODEL"
      ],
      "metadata": {
        "id": "P7FQnX3y_pDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Chroma_database=Chroma.from_documents(documents=splited_data,# OUT DATA\n",
        "                      embedding=EMB_MODEL,#EMBIDDING MODEL\n",
        "                      persist_directory='./chroma_DB_DATA')# TO SAVE THE DATABASE DATA"
      ],
      "metadata": {
        "id": "5G29kN5b9Gvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chroma_database\n",
        "# we can axcess this chroma.sqlite3 data base at leftside floder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC2QRBdx97qj",
        "outputId": "eaf715fc-353c-4a60-dc85-671f8065815a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7f7676266080>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASS A QUEARY (QUESTION)\n",
        "- TO VECTOR DATA_BASE"
      ],
      "metadata": {
        "id": "_GPQC3LvCEdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queary='in which year datascience came into field'\n",
        "\n",
        "output=Chroma_database.similarity_search(queary)\n",
        "output[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "_pIrWfPlCL5g",
        "outputId": "baa70e05-42f7-411d-ae32-0ccb7a58081b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Stanford professor David Donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data-science program. He describes data science as an applied field growing out of traditional statistics.[20]\\n\\nEtymology\\nEarly usage\\nIn 1962, John Tukey described a field he called \"data analysis\", which resembles modern data science.[20] In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C. F. Jeff Wu used the term \"data science\" for the first time as an alternative name for statistics.[21] Later, attendees at a 1992 statistics symposium at the University of Montpellier  II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.[22][23]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DONE**"
      ],
      "metadata": {
        "id": "m7skNTDo955r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOW WILL PERFORM BY USING PDF FILE**\n"
      ],
      "metadata": {
        "id": "iPXv5p0gxgSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- IMPORT REQUIRED PACKAGES\n",
        "- pip install pyPdf"
      ],
      "metadata": {
        "id": "IijiBJPZxgYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IF ANY PACKAGE IS NOT WORKING DO PIP INSTALL**"
      ],
      "metadata": {
        "id": "J_9E13wq8Z0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "UkG10ps160nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD THE PDF_FILE"
      ],
      "metadata": {
        "id": "4ts33XHc6yus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path=PyPDFLoader('/content/usig_sports_rules_-_cricket.pdf')\n",
        "pdf_file=path.load()"
      ],
      "metadata": {
        "id": "MjbGTBPv_uCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPLIT THE DOCUMENT"
      ],
      "metadata": {
        "id": "-PLeUkc-xgbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split=CharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
        "splited_data=split.split_documents(pdf_file)\n",
        "print(splited_data[0].page_content)\n",
        "print(len(splited_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8duL4FPA0Zl",
        "outputId": "97553b7b-af5f-4721-b6ce-0b9843e67509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cricket Rules  \n",
            " \n",
            "Introduction  \n",
            "The United State Ismaili Games is a high -calibre international sports tournament \n",
            "advocating excellence, healthy competition and sportsmanship by complying with \n",
            "international standards established by the various international sports federations.  \n",
            "Click here for more information on the Standard Twenty20 International Match Playing \n",
            "Conditions from the official governing body ( ICC - Men’s T20 Playing Conditions ) \n",
            " \n",
            "Highlights  \n",
            "● All matches will be played according to the Standard Twenty20 International \n",
            "Match Playing Conditions established by the International Cricket Council (ICC).  \n",
            "Each team will have a maximum of twenty (20) overs. The umpire will have the \n",
            "authority  to reduce the number of overs. All adjustments in terms of maximum \n",
            "over by a bowler or field restrictions will be adjusted accordingly.  \n",
            "● A bowler can bowl a maximum of four (4) overs  \n",
            "● If the bowler delivers the ball without some part of his front foot (eith er grounded \n",
            "or raised) behind the popping crease, or if his back foot does not “land within and \n",
            "not touch  the return crease”, this delivery is ruled a no ball.  It costs one (1) run \n",
            "and his next delivery is designated a “free hit”, from which the batsman c an only \n",
            "be dismissed through a run out, as is the case for the original “no ball”.\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONVERT INTO EMBIDDINGS"
      ],
      "metadata": {
        "id": "SmURYft8BaVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embidding_model=SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n",
        "embidding_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6SvUvh4BlFn",
        "outputId": "4df466fa-eb54-4d3a-b7aa-0c17ba7ba128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              "), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STORE IN VECTOR DATABASE"
      ],
      "metadata": {
        "id": "5FHhxUbSBha2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_DB=Chroma.from_documents(documents=splited_data,\n",
        "                                embedding=embidding_model)\n",
        "vector_DB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6pQLIGZB6Zo",
        "outputId": "a1b7bdec-b401-4c58-a0cf-c35f88bdd34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7f7660ceba30>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASS NEW QUEARY"
      ],
      "metadata": {
        "id": "vUyFov0oxger"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queary='what is time taken between one over to another over'\n",
        "output=vector_DB.similarity_search(queary)\n",
        "output[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "0UaoYN8eCu5i",
        "outputId": "8fd7d540-6e74-44c0-d55d-127cba395597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cricket Rules  \\nminutes duration. In reduced over matches, the interval will be cut to ten (10) \\nminutes.  \\nLength of innings  \\n● Each team shall bat for twenty (20) overs unless all out earlier  \\n● If the team fielding first (1st) fails to bowl the required number of overs by the \\nscheduled time for cessation of the first (1st) innings, play shall continue until the \\nrequired number of overs h as been bowled. The interval shall not be extended \\nand the second (2nd) session shall commence at the scheduled  time. The team \\nbatting second (2nd) shall receive its full quota of twenty (20) overs irrespective of \\nthe number of overs it bowled in the scheduled time for the cessation of the first \\n(1st) innings.  \\n● If the team batting first (1st) is dismissed in less than twenty (20) overs, the team \\nbatting second (2nd) shall be entitled to bat for twenty (20) overs  \\n● If the team fielding second (2nd) fails to bowl twenty (20) overs by the scheduled \\ncessation time, the hours of play shall be extended until the required number of \\novers has been bowled or a result is achieved  \\nDelayed or Interrupted Matches  \\nPowerplay overs in an interrupted / delayed mat ch \\nIn circumstances when the number of overs of the batting team is reduced, the number \\nof Powerplay overs shall be reduced in accordance with the table below. For the sake of \\nclarity, it should be noted that the table shall apply to both the 1st and 2nd i nnings of the \\nmatch.      \\nNo. of Overs ( Inns)                                 PowerPlay Overs  \\n19-20      06 \\n15-18      05 \\n12-14      04 \\n09-11      03'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ======================================================================="
      ],
      "metadata": {
        "id": "7pEPCOjWxghO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG APPLICATION BY GEMINI_MODEL_EMBIDDINGS"
      ],
      "metadata": {
        "id": "HfUrtOvPxgjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GKwvM9QITLl",
        "outputId": "849f47da-5a54-4c43-8c77-b135e6e7c1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.7)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.2.9)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.5 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.5)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.5->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (0.1.82)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain-google-genai) (8.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.18.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.63.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain-google-genai) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD THE DOCUMENT**"
      ],
      "metadata": {
        "id": "iyiHIVwPxgmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- THIS PACKAGE IS REQUIRD FOR EMBIDDINGS"
      ],
      "metadata": {
        "id": "sfZJmpisJfD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "htdtleG1JC-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=PyPDFLoader('/content/usig_sports_rules_-_cricket.pdf')\n",
        "pdf_file=path.load()"
      ],
      "metadata": {
        "id": "u2qRlmZnEikk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPLIT THE DOCUMENT"
      ],
      "metadata": {
        "id": "GOa6oBhDJsY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split=CharacterTextSplitter(chunk_size=1000,chunk_overlap=0)\n",
        "splited_data=split.split_documents(pdf_file)\n",
        "print(splited_data[0].page_content)\n",
        "print(len(splited_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ikCPX1KoE8",
        "outputId": "fc013056-ad2e-4829-a54f-aad1aa3cab62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cricket Rules  \n",
            " \n",
            "Introduction  \n",
            "The United State Ismaili Games is a high -calibre international sports tournament \n",
            "advocating excellence, healthy competition and sportsmanship by complying with \n",
            "international standards established by the various international sports federations.  \n",
            "Click here for more information on the Standard Twenty20 International Match Playing \n",
            "Conditions from the official governing body ( ICC - Men’s T20 Playing Conditions ) \n",
            " \n",
            "Highlights  \n",
            "● All matches will be played according to the Standard Twenty20 International \n",
            "Match Playing Conditions established by the International Cricket Council (ICC).  \n",
            "Each team will have a maximum of twenty (20) overs. The umpire will have the \n",
            "authority  to reduce the number of overs. All adjustments in terms of maximum \n",
            "over by a bowler or field restrictions will be adjusted accordingly.  \n",
            "● A bowler can bowl a maximum of four (4) overs  \n",
            "● If the bowler delivers the ball without some part of his front foot (eith er grounded \n",
            "or raised) behind the popping crease, or if his back foot does not “land within and \n",
            "not touch  the return crease”, this delivery is ruled a no ball.  It costs one (1) run \n",
            "and his next delivery is designated a “free hit”, from which the batsman c an only \n",
            "be dismissed through a run out, as is the case for the original “no ball”.\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EMBIDDINGS"
      ],
      "metadata": {
        "id": "gaL5RMxWK3wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_model=GoogleGenerativeAIEmbeddings(model='models/embidding-001',google_api_key='AIzaSyD6J_H8yUGr4pG-ub0wclElEZwhpFna6ak')\n",
        "emb_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmjvLq1TK6Og",
        "outputId": "466c8241-0692-4216-8619-0220e994e28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleGenerativeAIEmbeddings(client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x78ef0111ba00>, model='models/embidding-001', task_type=None, google_api_key=SecretStr('**********'), credentials=None, client_options=None, transport=None, request_options=None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VECTOR DATABASE(Chroma)"
      ],
      "metadata": {
        "id": "9aJpL3t8xgpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chroma_db=Chroma.from_documents(documents=splited_data,\n",
        "                      embedding=emb_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "Y4gF96-BMh2v",
        "outputId": "f46432c0-aa65-4211-bb48-bf92ebf2787e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "GoogleGenerativeAIError",
          "evalue": "Error embedding content: 404 models/embidding-001 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"models/embidding-001 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:173.194.203.95:443 {created_time:\"2024-06-25T16:20:12.577811347+00:00\", grpc_status:5, grpc_message:\"models/embidding-001 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods.\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/embeddings.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 result = self.client.batch_embed_contents(\n\u001b[0m\u001b[1;32m    226\u001b[0m                     \u001b[0mBatchEmbedContentsRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mbatch_embed_contents\u001b[0;34m(self, request, model, requests, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1366\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 models/embidding-001 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0c42a23b8bad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chroma_db=Chroma.from_documents(documents=splited_data,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       embedding=emb_model)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_chroma/vectorstores.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         return cls.from_texts(\n\u001b[0m\u001b[1;32m    798\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_chroma/vectorstores.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 )\n\u001b[1;32m    760\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mchroma_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchroma_collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_chroma/vectorstores.py\u001b[0m in \u001b[0;36madd_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# fill metadatas with empty dicts if somebody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/embeddings.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 )\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mGoogleGenerativeAIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error embedding content: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: 404 models/embidding-001 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rvd1xM5TxgsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BQkyxc2IxgvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y5asRVa_xgyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xf6VvS6gxg01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UUr95b-6xg3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1yph1vq6xg6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WX0GEBX9xg9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d_m-N7SqxhAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7g-jJTnYxhC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2HxbugStxhFv"
      }
    }
  ]
}